{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Start\n",
    "1. `kubectl`:\n",
    "    * cmd, powershell\n",
    "\n",
    "2. `minikube`:\n",
    "    * cmd, powershell\n",
    "\n",
    "3. `kind`\n",
    "    * cmd, powershell\n",
    "\n",
    "4. kubeflow pipelines:\n",
    "    * `pip install kfp`\n",
    "\n",
    "5. Start Docker Desktop\n",
    "\n",
    "### QuickStart\n",
    "6. Run in cmd: `kind create cluster --name=<clustername>`\n",
    "\n",
    "7. Run: `kubectl cluster-info --context <kind-clustername>`\n",
    "\n",
    "7. Run : `deploy_kubeflow_pipelines.zsh` \n",
    "\n",
    "8. Run the command below:D\n",
    "    ```bash\n",
    "    kubectl port-forward -n kubeflow svc/ml-pipeline-ui 8080:80\n",
    "    ```  \n",
    "\n",
    "9. Allow the Kubeflow Pipelines SDK to talk to the cluster via the following Python code:\n",
    "    ```python\n",
    "    import kfp\n",
    "    client = kfp.Client(host=\"http://localhost:8080\")\n",
    "    ```\n",
    "\n",
    "\n",
    "* Official Guides:\n",
    "    * [Deploying Kubeflow Pipelines as stand alone service](https://www.kubeflow.org/docs/components/pipelines/operator-guides/installation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda\\envs\\mle_proj\\Lib\\site-packages\\kfp\\client\\client.py:159: FutureWarning: This client only works with Kubeflow Pipeline v2.0.0-beta.2 and later versions.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "client = kfp.Client(host=\"http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from kfp import Client\n",
    "from kfp import dsl\n",
    "from kfp.dsl import Dataset\n",
    "from kfp.dsl import Input\n",
    "from kfp.dsl import Model\n",
    "from kfp.dsl import Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Components for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda\\envs\\mle_proj\\Lib\\site-packages\\kfp\\dsl\\component_decorator.py:121: FutureWarning: The default base_image used by the @dsl.component decorator will switch from 'python:3.8' to 'python:3.9' on Oct 1, 2024. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.9.\n",
      "  return component_factory.create_component_from_func(\n"
     ]
    }
   ],
   "source": [
    "@dsl.component(packages_to_install=['pandas'])\n",
    "def create_dataset(iris_dataset: Output[Dataset]):\n",
    "    import pandas as pd\n",
    "\n",
    "    csv_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "    col_names = [\n",
    "        \"Sepal_Length\", \"Sepal_Width\", \"Petal_Length\", \"Petal_Width\", \"Labels\"\n",
    "    ]\n",
    "    df = pd.read_csv(csv_url)\n",
    "    df.columns = col_names\n",
    "\n",
    "    with open(iris_dataset.path, 'w') as f:\n",
    "        df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(packages_to_install=['pandas', 'scikit-learn'])\n",
    "def normalize_dataset(\n",
    "    input_iris_dataset: Input[Dataset],\n",
    "    normalized_iris_dataset: Output[Dataset],\n",
    "    standard_scaler: bool,\n",
    "    min_max_scaler: bool,\n",
    "):\n",
    "    if standard_scaler is min_max_scaler:\n",
    "        raise ValueError(\n",
    "            'Exactly one of standard_scaler or min_max_scaler must be True.')\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    with open(input_iris_dataset.path) as f:\n",
    "        df = pd.read_csv(f)\n",
    "    labels = df.pop('Labels')\n",
    "\n",
    "    if standard_scaler:\n",
    "        scaler = StandardScaler()\n",
    "    if min_max_scaler:\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "    df = pd.DataFrame(scaler.fit_transform(df))\n",
    "    df['Labels'] = labels\n",
    "    with open(normalized_iris_dataset.path, 'w') as f:\n",
    "        df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(packages_to_install=['pandas', 'scikit-learn'])\n",
    "def train_model(\n",
    "    normalized_iris_dataset: Input[Dataset],\n",
    "    model: Output[Model],\n",
    "    n_neighbors: int,\n",
    "):\n",
    "    import pickle\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    with open(normalized_iris_dataset.path) as f:\n",
    "        df = pd.read_csv(f)\n",
    "\n",
    "    y = df.pop('Labels')\n",
    "    X = df\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    with open(model.path, 'wb') as f:\n",
    "        pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='iris-training-pipeline')\n",
    "def my_pipeline(\n",
    "    standard_scaler: bool,\n",
    "    min_max_scaler: bool,\n",
    "    neighbors: List[int],\n",
    "):\n",
    "    create_dataset_task = create_dataset()\n",
    "\n",
    "    normalize_dataset_task = normalize_dataset(\n",
    "        input_iris_dataset=create_dataset_task.outputs['iris_dataset'],\n",
    "        standard_scaler=True,\n",
    "        min_max_scaler=False)\n",
    "\n",
    "    with dsl.ParallelFor(neighbors) as n_neighbors:\n",
    "        train_model(\n",
    "            normalized_iris_dataset=normalize_dataset_task.outputs['normalized_iris_dataset'],\n",
    "            n_neighbors=n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submet the Pipeline to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8080/#/experiments/details/1d2cbd48-dbfb-4399-9169-5daaac9e5811\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8080/#/runs/details/dec36986-cf31-4733-948a-37497c8a2e53\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/#/runs/details/dec36986-cf31-4733-948a-37497c8a2e53\n"
     ]
    }
   ],
   "source": [
    "endpoint = 'http://localhost:8080' #as a result of port-forwarding.\n",
    "# running kubectl cluster-info --context kind-testcluster (this is cluster name)\n",
    "# endpoint = 'https://127.0.0.1:54463' \n",
    "kfp_client = Client(host=endpoint)\n",
    "run = kfp_client.create_run_from_pipeline_func(\n",
    "    my_pipeline,\n",
    "    #mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE,\n",
    "    arguments={\n",
    "        'min_max_scaler': True,\n",
    "        'standard_scaler': False,\n",
    "        'neighbors': [3, 6, 9]\n",
    "    },\n",
    ")\n",
    "url = f'{endpoint}/#/runs/details/{run.run_id}'\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
